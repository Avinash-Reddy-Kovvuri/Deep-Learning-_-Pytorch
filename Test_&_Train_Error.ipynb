{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avinash-Reddy-Kovvuri/Deep-Learning-_-Pytorch/blob/main/Test_%26_Train_Error.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ys-cU7bjam6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = model.to(device)\n",
        "print(f\"{device} is using.\")"
      ],
      "metadata": {
        "id": "4i3dZHm2gUT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defb2fb8-514d-406b-e0e5-af9c21e9856a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is using.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYDoJW2Jjgup"
      },
      "outputs": [],
      "source": [
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nwxYprwjno-"
      },
      "outputs": [],
      "source": [
        "# Initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGen4NzojvU9"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMmTZyydjoJK"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    eoch_loss = 0\n",
        "    n = 0\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X.to(device))\n",
        "        loss = loss_fn(pred.to(device), y.to(device))\n",
        "      \n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            eoch_loss += loss\n",
        "            n +=1\n",
        "    return eoch_loss/n\n",
        "      \n",
        "    \n",
        "       \n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    \n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X.to(device))\n",
        "            test_loss += loss_fn(pred.to(device), y.to(device)).item()\n",
        "            correct += ((pred.to(device)).argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-65xQX79j0ew",
        "outputId": "37cc1e7e-1056-409e-e0e2-814285ebd643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.303483  [    0/60000]\n",
            "loss: 2.294619  [ 6400/60000]\n",
            "loss: 2.288193  [12800/60000]\n",
            "loss: 2.280188  [19200/60000]\n",
            "loss: 2.284165  [25600/60000]\n",
            "loss: 2.279289  [32000/60000]\n",
            "loss: 2.270032  [38400/60000]\n",
            "loss: 2.278471  [44800/60000]\n",
            "loss: 2.256738  [51200/60000]\n",
            "loss: 2.256135  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 2.253032 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.252514  [    0/60000]\n",
            "loss: 2.241789  [ 6400/60000]\n",
            "loss: 2.248965  [12800/60000]\n",
            "loss: 2.216287  [19200/60000]\n",
            "loss: 2.233266  [25600/60000]\n",
            "loss: 2.227056  [32000/60000]\n",
            "loss: 2.206106  [38400/60000]\n",
            "loss: 2.230431  [44800/60000]\n",
            "loss: 2.191923  [51200/60000]\n",
            "loss: 2.188550  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 54.5%, Avg loss: 2.184840 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.182722  [    0/60000]\n",
            "loss: 2.165034  [ 6400/60000]\n",
            "loss: 2.189430  [12800/60000]\n",
            "loss: 2.122196  [19200/60000]\n",
            "loss: 2.154154  [25600/60000]\n",
            "loss: 2.144970  [32000/60000]\n",
            "loss: 2.104106  [38400/60000]\n",
            "loss: 2.149556  [44800/60000]\n",
            "loss: 2.086523  [51200/60000]\n",
            "loss: 2.078281  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 2.070329 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.067075  [    0/60000]\n",
            "loss: 2.035482  [ 6400/60000]\n",
            "loss: 2.085977  [12800/60000]\n",
            "loss: 1.968056  [19200/60000]\n",
            "loss: 2.016227  [25600/60000]\n",
            "loss: 1.999431  [32000/60000]\n",
            "loss: 1.932638  [38400/60000]\n",
            "loss: 2.006649  [44800/60000]\n",
            "loss: 1.907687  [51200/60000]\n",
            "loss: 1.892356  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.7%, Avg loss: 1.875712 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.875627  [    0/60000]\n",
            "loss: 1.820617  [ 6400/60000]\n",
            "loss: 1.902628  [12800/60000]\n",
            "loss: 1.728213  [19200/60000]\n",
            "loss: 1.780058  [25600/60000]\n",
            "loss: 1.753364  [32000/60000]\n",
            "loss: 1.668922  [38400/60000]\n",
            "loss: 1.779938  [44800/60000]\n",
            "loss: 1.638154  [51200/60000]\n",
            "loss: 1.616107  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 74.0%, Avg loss: 1.586236 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.601635  [    0/60000]\n",
            "loss: 1.513052  [ 6400/60000]\n",
            "loss: 1.619253  [12800/60000]\n",
            "loss: 1.418573  [19200/60000]\n",
            "loss: 1.451516  [25600/60000]\n",
            "loss: 1.423722  [32000/60000]\n",
            "loss: 1.341793  [38400/60000]\n",
            "loss: 1.488481  [44800/60000]\n",
            "loss: 1.330644  [51200/60000]\n",
            "loss: 1.299420  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 1.262521 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.306061  [    0/60000]\n",
            "loss: 1.190699  [ 6400/60000]\n",
            "loss: 1.296853  [12800/60000]\n",
            "loss: 1.125368  [19200/60000]\n",
            "loss: 1.136713  [25600/60000]\n",
            "loss: 1.114674  [32000/60000]\n",
            "loss: 1.047771  [38400/60000]\n",
            "loss: 1.215093  [44800/60000]\n",
            "loss: 1.037949  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 1.004106 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.074191  [    0/60000]\n",
            "loss: 0.949456  [ 6400/60000]\n",
            "loss: 1.035423  [12800/60000]\n",
            "loss: 0.913169  [19200/60000]\n",
            "loss: 0.913962  [25600/60000]\n",
            "loss: 0.895356  [32000/60000]\n",
            "loss: 0.839781  [38400/60000]\n",
            "loss: 1.013209  [44800/60000]\n",
            "loss: 0.909905  [51200/60000]\n",
            "loss: 0.862450  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.1%, Avg loss: 0.829802 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.914946  [    0/60000]\n",
            "loss: 0.789410  [ 6400/60000]\n",
            "loss: 0.854717  [12800/60000]\n",
            "loss: 0.773158  [19200/60000]\n",
            "loss: 0.768342  [25600/60000]\n",
            "loss: 0.752669  [32000/60000]\n",
            "loss: 0.699449  [38400/60000]\n",
            "loss: 0.874112  [44800/60000]\n",
            "loss: 0.796075  [51200/60000]\n",
            "loss: 0.749381  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.713692 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.804922  [    0/60000]\n",
            "loss: 0.680528  [ 6400/60000]\n",
            "loss: 0.731230  [12800/60000]\n",
            "loss: 0.679982  [19200/60000]\n",
            "loss: 0.669454  [25600/60000]\n",
            "loss: 0.658552  [32000/60000]\n",
            "loss: 0.601004  [38400/60000]\n",
            "loss: 0.777805  [44800/60000]\n",
            "loss: 0.715546  [51200/60000]\n",
            "loss: 0.674599  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.633449 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.725873  [    0/60000]\n",
            "loss: 0.602477  [ 6400/60000]\n",
            "loss: 0.644147  [12800/60000]\n",
            "loss: 0.615774  [19200/60000]\n",
            "loss: 0.598715  [25600/60000]\n",
            "loss: 0.594352  [32000/60000]\n",
            "loss: 0.529128  [38400/60000]\n",
            "loss: 0.709376  [44800/60000]\n",
            "loss: 0.655334  [51200/60000]\n",
            "loss: 0.623316  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.575611 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.666431  [    0/60000]\n",
            "loss: 0.543932  [ 6400/60000]\n",
            "loss: 0.580406  [12800/60000]\n",
            "loss: 0.569724  [19200/60000]\n",
            "loss: 0.546024  [25600/60000]\n",
            "loss: 0.548997  [32000/60000]\n",
            "loss: 0.474980  [38400/60000]\n",
            "loss: 0.659250  [44800/60000]\n",
            "loss: 0.608478  [51200/60000]\n",
            "loss: 0.586836  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.532275 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.619889  [    0/60000]\n",
            "loss: 0.498576  [ 6400/60000]\n",
            "loss: 0.531908  [12800/60000]\n",
            "loss: 0.535378  [19200/60000]\n",
            "loss: 0.505421  [25600/60000]\n",
            "loss: 0.515824  [32000/60000]\n",
            "loss: 0.433195  [38400/60000]\n",
            "loss: 0.621254  [44800/60000]\n",
            "loss: 0.571139  [51200/60000]\n",
            "loss: 0.559946  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.498693 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.582152  [    0/60000]\n",
            "loss: 0.462657  [ 6400/60000]\n",
            "loss: 0.493600  [12800/60000]\n",
            "loss: 0.508827  [19200/60000]\n",
            "loss: 0.473188  [25600/60000]\n",
            "loss: 0.490790  [32000/60000]\n",
            "loss: 0.400235  [38400/60000]\n",
            "loss: 0.591433  [44800/60000]\n",
            "loss: 0.540906  [51200/60000]\n",
            "loss: 0.539438  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.471933 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.550630  [    0/60000]\n",
            "loss: 0.433850  [ 6400/60000]\n",
            "loss: 0.462406  [12800/60000]\n",
            "loss: 0.487795  [19200/60000]\n",
            "loss: 0.446915  [25600/60000]\n",
            "loss: 0.471383  [32000/60000]\n",
            "loss: 0.373676  [38400/60000]\n",
            "loss: 0.567353  [44800/60000]\n",
            "loss: 0.516027  [51200/60000]\n",
            "loss: 0.523452  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.450119 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.523705  [    0/60000]\n",
            "loss: 0.410467  [ 6400/60000]\n",
            "loss: 0.436344  [12800/60000]\n",
            "loss: 0.470679  [19200/60000]\n",
            "loss: 0.425090  [25600/60000]\n",
            "loss: 0.455849  [32000/60000]\n",
            "loss: 0.351890  [38400/60000]\n",
            "loss: 0.547478  [44800/60000]\n",
            "loss: 0.495169  [51200/60000]\n",
            "loss: 0.510714  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.432006 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.500362  [    0/60000]\n",
            "loss: 0.391207  [ 6400/60000]\n",
            "loss: 0.414099  [12800/60000]\n",
            "loss: 0.456428  [19200/60000]\n",
            "loss: 0.406631  [25600/60000]\n",
            "loss: 0.443079  [32000/60000]\n",
            "loss: 0.333684  [38400/60000]\n",
            "loss: 0.530682  [44800/60000]\n",
            "loss: 0.477383  [51200/60000]\n",
            "loss: 0.500431  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.416732 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.479860  [    0/60000]\n",
            "loss: 0.375196  [ 6400/60000]\n",
            "loss: 0.394769  [12800/60000]\n",
            "loss: 0.444419  [19200/60000]\n",
            "loss: 0.390848  [25600/60000]\n",
            "loss: 0.432286  [32000/60000]\n",
            "loss: 0.318300  [38400/60000]\n",
            "loss: 0.516224  [44800/60000]\n",
            "loss: 0.462072  [51200/60000]\n",
            "loss: 0.491956  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.403682 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.461575  [    0/60000]\n",
            "loss: 0.361830  [ 6400/60000]\n",
            "loss: 0.377703  [12800/60000]\n",
            "loss: 0.434109  [19200/60000]\n",
            "loss: 0.377192  [25600/60000]\n",
            "loss: 0.422946  [32000/60000]\n",
            "loss: 0.305106  [38400/60000]\n",
            "loss: 0.503604  [44800/60000]\n",
            "loss: 0.448767  [51200/60000]\n",
            "loss: 0.484872  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.392391 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.445181  [    0/60000]\n",
            "loss: 0.350549  [ 6400/60000]\n",
            "loss: 0.362492  [12800/60000]\n",
            "loss: 0.425056  [19200/60000]\n",
            "loss: 0.365216  [25600/60000]\n",
            "loss: 0.414638  [32000/60000]\n",
            "loss: 0.293656  [38400/60000]\n",
            "loss: 0.492473  [44800/60000]\n",
            "loss: 0.437021  [51200/60000]\n",
            "loss: 0.478862  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.2%, Avg loss: 0.382522 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.430388  [    0/60000]\n",
            "loss: 0.340938  [ 6400/60000]\n",
            "loss: 0.348794  [12800/60000]\n",
            "loss: 0.417098  [19200/60000]\n",
            "loss: 0.354581  [25600/60000]\n",
            "loss: 0.407182  [32000/60000]\n",
            "loss: 0.283630  [38400/60000]\n",
            "loss: 0.482556  [44800/60000]\n",
            "loss: 0.426514  [51200/60000]\n",
            "loss: 0.473622  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.373810 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.416922  [    0/60000]\n",
            "loss: 0.332671  [ 6400/60000]\n",
            "loss: 0.336394  [12800/60000]\n",
            "loss: 0.410040  [19200/60000]\n",
            "loss: 0.345035  [25600/60000]\n",
            "loss: 0.400377  [32000/60000]\n",
            "loss: 0.274827  [38400/60000]\n",
            "loss: 0.473600  [44800/60000]\n",
            "loss: 0.417025  [51200/60000]\n",
            "loss: 0.469030  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.7%, Avg loss: 0.366053 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.404548  [    0/60000]\n",
            "loss: 0.325514  [ 6400/60000]\n",
            "loss: 0.325069  [12800/60000]\n",
            "loss: 0.403757  [19200/60000]\n",
            "loss: 0.336462  [25600/60000]\n",
            "loss: 0.394142  [32000/60000]\n",
            "loss: 0.267003  [38400/60000]\n",
            "loss: 0.465450  [44800/60000]\n",
            "loss: 0.408431  [51200/60000]\n",
            "loss: 0.464944  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.359084 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.393128  [    0/60000]\n",
            "loss: 0.319223  [ 6400/60000]\n",
            "loss: 0.314690  [12800/60000]\n",
            "loss: 0.398095  [19200/60000]\n",
            "loss: 0.328672  [25600/60000]\n",
            "loss: 0.388314  [32000/60000]\n",
            "loss: 0.259997  [38400/60000]\n",
            "loss: 0.458029  [44800/60000]\n",
            "loss: 0.400567  [51200/60000]\n",
            "loss: 0.461279  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.352773 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.382515  [    0/60000]\n",
            "loss: 0.313719  [ 6400/60000]\n",
            "loss: 0.305117  [12800/60000]\n",
            "loss: 0.392943  [19200/60000]\n",
            "loss: 0.321474  [25600/60000]\n",
            "loss: 0.382826  [32000/60000]\n",
            "loss: 0.253733  [38400/60000]\n",
            "loss: 0.451219  [44800/60000]\n",
            "loss: 0.393291  [51200/60000]\n",
            "loss: 0.457994  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.1%, Avg loss: 0.347020 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.372598  [    0/60000]\n",
            "loss: 0.308825  [ 6400/60000]\n",
            "loss: 0.296262  [12800/60000]\n",
            "loss: 0.388229  [19200/60000]\n",
            "loss: 0.314844  [25600/60000]\n",
            "loss: 0.377707  [32000/60000]\n",
            "loss: 0.248070  [38400/60000]\n",
            "loss: 0.444918  [44800/60000]\n",
            "loss: 0.386539  [51200/60000]\n",
            "loss: 0.454922  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.3%, Avg loss: 0.341733 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.363301  [    0/60000]\n",
            "loss: 0.304445  [ 6400/60000]\n",
            "loss: 0.288044  [12800/60000]\n",
            "loss: 0.383859  [19200/60000]\n",
            "loss: 0.308663  [25600/60000]\n",
            "loss: 0.372856  [32000/60000]\n",
            "loss: 0.242963  [38400/60000]\n",
            "loss: 0.439069  [44800/60000]\n",
            "loss: 0.380141  [51200/60000]\n",
            "loss: 0.451985  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.336842 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.354578  [    0/60000]\n",
            "loss: 0.300446  [ 6400/60000]\n",
            "loss: 0.280396  [12800/60000]\n",
            "loss: 0.379749  [19200/60000]\n",
            "loss: 0.302934  [25600/60000]\n",
            "loss: 0.368285  [32000/60000]\n",
            "loss: 0.238315  [38400/60000]\n",
            "loss: 0.433660  [44800/60000]\n",
            "loss: 0.374110  [51200/60000]\n",
            "loss: 0.449209  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.332289 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.346323  [    0/60000]\n",
            "loss: 0.296775  [ 6400/60000]\n",
            "loss: 0.273281  [12800/60000]\n",
            "loss: 0.375904  [19200/60000]\n",
            "loss: 0.297547  [25600/60000]\n",
            "loss: 0.363986  [32000/60000]\n",
            "loss: 0.234031  [38400/60000]\n",
            "loss: 0.428616  [44800/60000]\n",
            "loss: 0.368385  [51200/60000]\n",
            "loss: 0.446551  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 0.328033 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.338480  [    0/60000]\n",
            "loss: 0.293436  [ 6400/60000]\n",
            "loss: 0.266607  [12800/60000]\n",
            "loss: 0.372270  [19200/60000]\n",
            "loss: 0.292404  [25600/60000]\n",
            "loss: 0.359926  [32000/60000]\n",
            "loss: 0.230109  [38400/60000]\n",
            "loss: 0.423886  [44800/60000]\n",
            "loss: 0.362904  [51200/60000]\n",
            "loss: 0.443930  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.324034 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.331044  [    0/60000]\n",
            "loss: 0.290421  [ 6400/60000]\n",
            "loss: 0.260345  [12800/60000]\n",
            "loss: 0.368844  [19200/60000]\n",
            "loss: 0.287475  [25600/60000]\n",
            "loss: 0.356074  [32000/60000]\n",
            "loss: 0.226491  [38400/60000]\n",
            "loss: 0.419443  [44800/60000]\n",
            "loss: 0.357534  [51200/60000]\n",
            "loss: 0.441362  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.9%, Avg loss: 0.320259 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.323959  [    0/60000]\n",
            "loss: 0.287595  [ 6400/60000]\n",
            "loss: 0.254486  [12800/60000]\n",
            "loss: 0.365620  [19200/60000]\n",
            "loss: 0.282818  [25600/60000]\n",
            "loss: 0.352419  [32000/60000]\n",
            "loss: 0.223137  [38400/60000]\n",
            "loss: 0.415269  [44800/60000]\n",
            "loss: 0.352361  [51200/60000]\n",
            "loss: 0.438796  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.316682 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.317229  [    0/60000]\n",
            "loss: 0.284939  [ 6400/60000]\n",
            "loss: 0.248997  [12800/60000]\n",
            "loss: 0.362494  [19200/60000]\n",
            "loss: 0.278354  [25600/60000]\n",
            "loss: 0.348941  [32000/60000]\n",
            "loss: 0.220039  [38400/60000]\n",
            "loss: 0.411336  [44800/60000]\n",
            "loss: 0.347318  [51200/60000]\n",
            "loss: 0.436287  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.313283 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.310823  [    0/60000]\n",
            "loss: 0.282433  [ 6400/60000]\n",
            "loss: 0.243850  [12800/60000]\n",
            "loss: 0.359483  [19200/60000]\n",
            "loss: 0.274090  [25600/60000]\n",
            "loss: 0.345584  [32000/60000]\n",
            "loss: 0.217144  [38400/60000]\n",
            "loss: 0.407643  [44800/60000]\n",
            "loss: 0.342493  [51200/60000]\n",
            "loss: 0.433838  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.310037 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.304681  [    0/60000]\n",
            "loss: 0.280048  [ 6400/60000]\n",
            "loss: 0.238993  [12800/60000]\n",
            "loss: 0.356619  [19200/60000]\n",
            "loss: 0.270004  [25600/60000]\n",
            "loss: 0.342385  [32000/60000]\n",
            "loss: 0.214431  [38400/60000]\n",
            "loss: 0.404134  [44800/60000]\n",
            "loss: 0.337828  [51200/60000]\n",
            "loss: 0.431463  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.306935 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.298790  [    0/60000]\n",
            "loss: 0.277793  [ 6400/60000]\n",
            "loss: 0.234433  [12800/60000]\n",
            "loss: 0.353838  [19200/60000]\n",
            "loss: 0.266058  [25600/60000]\n",
            "loss: 0.339310  [32000/60000]\n",
            "loss: 0.211890  [38400/60000]\n",
            "loss: 0.400808  [44800/60000]\n",
            "loss: 0.333337  [51200/60000]\n",
            "loss: 0.429134  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.3%, Avg loss: 0.303959 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.293115  [    0/60000]\n",
            "loss: 0.275634  [ 6400/60000]\n",
            "loss: 0.230114  [12800/60000]\n",
            "loss: 0.351210  [19200/60000]\n",
            "loss: 0.262226  [25600/60000]\n",
            "loss: 0.336375  [32000/60000]\n",
            "loss: 0.209517  [38400/60000]\n",
            "loss: 0.397586  [44800/60000]\n",
            "loss: 0.328949  [51200/60000]\n",
            "loss: 0.426847  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.301101 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.287642  [    0/60000]\n",
            "loss: 0.273581  [ 6400/60000]\n",
            "loss: 0.225994  [12800/60000]\n",
            "loss: 0.348645  [19200/60000]\n",
            "loss: 0.258487  [25600/60000]\n",
            "loss: 0.333595  [32000/60000]\n",
            "loss: 0.207286  [38400/60000]\n",
            "loss: 0.394533  [44800/60000]\n",
            "loss: 0.324693  [51200/60000]\n",
            "loss: 0.424609  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.298348 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.282353  [    0/60000]\n",
            "loss: 0.271572  [ 6400/60000]\n",
            "loss: 0.222089  [12800/60000]\n",
            "loss: 0.346142  [19200/60000]\n",
            "loss: 0.254842  [25600/60000]\n",
            "loss: 0.330921  [32000/60000]\n",
            "loss: 0.205161  [38400/60000]\n",
            "loss: 0.391597  [44800/60000]\n",
            "loss: 0.320518  [51200/60000]\n",
            "loss: 0.422376  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.295690 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.277259  [    0/60000]\n",
            "loss: 0.269635  [ 6400/60000]\n",
            "loss: 0.218378  [12800/60000]\n",
            "loss: 0.343667  [19200/60000]\n",
            "loss: 0.251306  [25600/60000]\n",
            "loss: 0.328355  [32000/60000]\n",
            "loss: 0.203095  [38400/60000]\n",
            "loss: 0.388838  [44800/60000]\n",
            "loss: 0.316361  [51200/60000]\n",
            "loss: 0.420128  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.293125 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.272364  [    0/60000]\n",
            "loss: 0.267774  [ 6400/60000]\n",
            "loss: 0.214880  [12800/60000]\n",
            "loss: 0.341203  [19200/60000]\n",
            "loss: 0.247906  [25600/60000]\n",
            "loss: 0.325920  [32000/60000]\n",
            "loss: 0.201155  [38400/60000]\n",
            "loss: 0.386143  [44800/60000]\n",
            "loss: 0.312297  [51200/60000]\n",
            "loss: 0.417928  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.290636 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.267609  [    0/60000]\n",
            "loss: 0.265980  [ 6400/60000]\n",
            "loss: 0.211549  [12800/60000]\n",
            "loss: 0.338781  [19200/60000]\n",
            "loss: 0.244586  [25600/60000]\n",
            "loss: 0.323608  [32000/60000]\n",
            "loss: 0.199290  [38400/60000]\n",
            "loss: 0.383582  [44800/60000]\n",
            "loss: 0.308334  [51200/60000]\n",
            "loss: 0.415693  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.288222 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.263018  [    0/60000]\n",
            "loss: 0.264221  [ 6400/60000]\n",
            "loss: 0.208339  [12800/60000]\n",
            "loss: 0.336473  [19200/60000]\n",
            "loss: 0.241362  [25600/60000]\n",
            "loss: 0.321359  [32000/60000]\n",
            "loss: 0.197497  [38400/60000]\n",
            "loss: 0.381142  [44800/60000]\n",
            "loss: 0.304511  [51200/60000]\n",
            "loss: 0.413466  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.9%, Avg loss: 0.285881 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.258615  [    0/60000]\n",
            "loss: 0.262527  [ 6400/60000]\n",
            "loss: 0.205284  [12800/60000]\n",
            "loss: 0.334270  [19200/60000]\n",
            "loss: 0.238237  [25600/60000]\n",
            "loss: 0.319180  [32000/60000]\n",
            "loss: 0.195737  [38400/60000]\n",
            "loss: 0.378784  [44800/60000]\n",
            "loss: 0.300696  [51200/60000]\n",
            "loss: 0.411251  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.283605 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.254332  [    0/60000]\n",
            "loss: 0.260904  [ 6400/60000]\n",
            "loss: 0.202364  [12800/60000]\n",
            "loss: 0.332141  [19200/60000]\n",
            "loss: 0.235165  [25600/60000]\n",
            "loss: 0.317116  [32000/60000]\n",
            "loss: 0.194031  [38400/60000]\n",
            "loss: 0.376466  [44800/60000]\n",
            "loss: 0.296978  [51200/60000]\n",
            "loss: 0.409016  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.1%, Avg loss: 0.281389 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.250169  [    0/60000]\n",
            "loss: 0.259254  [ 6400/60000]\n",
            "loss: 0.199554  [12800/60000]\n",
            "loss: 0.330102  [19200/60000]\n",
            "loss: 0.232200  [25600/60000]\n",
            "loss: 0.315089  [32000/60000]\n",
            "loss: 0.192346  [38400/60000]\n",
            "loss: 0.374239  [44800/60000]\n",
            "loss: 0.293305  [51200/60000]\n",
            "loss: 0.406759  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.279228 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.246135  [    0/60000]\n",
            "loss: 0.257660  [ 6400/60000]\n",
            "loss: 0.196874  [12800/60000]\n",
            "loss: 0.328087  [19200/60000]\n",
            "loss: 0.229336  [25600/60000]\n",
            "loss: 0.313143  [32000/60000]\n",
            "loss: 0.190672  [38400/60000]\n",
            "loss: 0.372109  [44800/60000]\n",
            "loss: 0.289729  [51200/60000]\n",
            "loss: 0.404533  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.277123 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.242193  [    0/60000]\n",
            "loss: 0.256107  [ 6400/60000]\n",
            "loss: 0.194292  [12800/60000]\n",
            "loss: 0.326124  [19200/60000]\n",
            "loss: 0.226542  [25600/60000]\n",
            "loss: 0.311208  [32000/60000]\n",
            "loss: 0.189035  [38400/60000]\n",
            "loss: 0.370035  [44800/60000]\n",
            "loss: 0.286230  [51200/60000]\n",
            "loss: 0.402360  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.275068 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.238332  [    0/60000]\n",
            "loss: 0.254677  [ 6400/60000]\n",
            "loss: 0.191791  [12800/60000]\n",
            "loss: 0.324150  [19200/60000]\n",
            "loss: 0.223861  [25600/60000]\n",
            "loss: 0.309345  [32000/60000]\n",
            "loss: 0.187424  [38400/60000]\n",
            "loss: 0.367994  [44800/60000]\n",
            "loss: 0.282766  [51200/60000]\n",
            "loss: 0.400202  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.273062 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.234609  [    0/60000]\n",
            "loss: 0.253285  [ 6400/60000]\n",
            "loss: 0.189394  [12800/60000]\n",
            "loss: 0.322217  [19200/60000]\n",
            "loss: 0.221285  [25600/60000]\n",
            "loss: 0.307525  [32000/60000]\n",
            "loss: 0.185873  [38400/60000]\n",
            "loss: 0.366034  [44800/60000]\n",
            "loss: 0.279372  [51200/60000]\n",
            "loss: 0.397993  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.271092 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "tr_los_li = []\n",
        "tes_los_li = []\n",
        "epochs = 50\n",
        "for t in range(epochs):\n",
        "\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
        "    tr_los_li.append(train_loss)\n",
        "    tes_los_li.append(test_loss)\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(pd.DataFrame(np.array(tr_los_li)),label=\"Train loss\")\n",
        "plt.plot(pd.DataFrame(np.array(tes_los_li)),label=\"Test loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f6hYGRn4uHP4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a47b94e4-bd20-4217-8ba0-f781065dd238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MQ-Nou-JVPxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Test & Train Error_ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGkXvT0K/t61mf2nHHbouE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}